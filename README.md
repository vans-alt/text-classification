ğŸ“¦ Text Classification with Transformers

ğŸ§  Overview

This project implements a binary text classification pipeline using Hugging Face Transformers and the IMDB dataset. The goal is to fine-tune a pre-trained transformer (DistilBERT) to classify movie reviews as **positive** or **negative**.

<pre>text-classification/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ text_classification_pipeline.ipynb      # End-to-end pipeline in Jupyter
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                               # Hyperparameters & model paths
â”‚   â”œâ”€â”€ data_preprocessing.py                   # Data cleaning, tokenization
â”‚   â”œâ”€â”€ model_utils.py                          # Load/save model, pipeline logic
â”‚   â”œâ”€â”€ train_model.py                          # Training using HuggingFace Trainer
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained/                                # Final fine-tuned model
â”‚   â”œâ”€â”€ tokenizer/                              # Tokenizer files
â”‚   â””â”€â”€ checkpoints/                            # Intermediate checkpoints
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ submission.md                           # Approach, learnings, future work
â”‚   â”œâ”€â”€ execution_report.md                     # CLI steps + screenshots
â”‚   â”œâ”€â”€ evaluation_metrics.json                 # Accuracy, Precision, Recall, F1
â”‚   â””â”€â”€ training_curve.png                      # Training vs. Eval F1 loss plot
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py                                # CLI entry point to train the model
â”‚
â”œâ”€â”€ requirements.txt                            # Python dependencies
â””â”€â”€ README.md                                    # Project overview & instructions
</pre>

ğŸ› ï¸ Setup

1. Clone this repository:

```bash
git clone <repo-url>
cd text-classification-pipeline
```

2. (Optional) Create a virtual environment:

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```


ğŸš€ How to Run

ğŸ“Œ Option 1: From notebook

Run `notebooks/text-classification.ipynb` in Google Colab or Jupyter Notebook for full pipeline.

ğŸ“Œ Option 2: From script

```bash
python train.py
```

ğŸ“Š Evaluation

| Metric    | Score  |
| --------- | -------|
| Accuracy  | ~0.905 |
| F1 Score  | ~0.906 |
| Precision | ~0.905 |
| Recall    | ~0.905 |

ğŸ“Œ Visualizations available in `reports/train loss, eval f1 plot.png`

ğŸ” Key Features

* Modular architecture (data, model, config separated)
* Easy experimentation with `Trainer`
* WANDB logging integrated
* Intermediate checkpoints and best model saving
* Ready to extend for multilingual classification (e.g. XLM-Roberta)


âœï¸ Author

Vanshita Gupta

ğŸª„ License

Open-source for educational purposes. Modify and reuse with attribution.

Happy fine-tuning! ğŸ¤—
"# text-classification" 
